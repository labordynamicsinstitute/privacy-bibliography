% Encoding: UTF-8

@Article{Abowd:JPC:2017,
  author   = {John M. Abowd},
  title    = {How Will Statistical Agencies Operate When All Data Are Private?},
  journal  = {Journal of Privacy and Confidentiality},
  year     = {2017},
  volume   = {7},
  number   = {3},
  note     = {Published version of Abowd:LDI:2016:30},
  doi      = {10.29012/jpc.v7i3.404},
  keywords = {Official Statistics, primary},
  url      = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/404},
}

@Article{abowd:fcsm:2016,
  author   = {Abowd, John M.},
  title    = {Why Statistical Agencies Need to Take Privacy-loss Budgets Seriously, and What It Means When They Do},
  journal  = {The 13th Biennial Federal Committee on Statistical Methodology (FCSM) Policy Conference},
  year     = {2016},
  month    = {12},
  note     = {\url{https://digitalcommons.ilr.cornell.edu/ldi/32/}},
  doi      = {N/A},
  keywords = {Official Statistics, primary},
  url      = {https://digitalcommons.ilr.cornell.edu/ldi/32/},
}

@Article{abowd:schmutte:BPEA:2015,
  author    = {John M. Abowd and Ian M. Schmutte},
  title     = {Economic analysis and statistical disclosure limitation},
  journal   = {Brookings Papers on Economic Activity},
  year      = {2015},
  pages     = {221--267},
  note      = {Spring},
  doi       = {10.1353/eca.2016.0004},
  keywords  = {Statistical Disclosure Limitation, SDL, primary},
  owner     = {John Abowd},
  timestamp = {2016.07.08},
  url       = {http://www.brookings.edu/~/media/Projects/BPEA/Spring-2015-Revised/AbowdText.pdf?la=en},
}

@Article{AbowdSchmutte:Privacy:AER,
  author   = {John M. Abowd and Ian M. Schmutte},
  title    = {An Economic Analysis of Privacy Protection and Statistical Accuracy as Social Choices},
  journal  = {American Economic Review},
  year     = {2019},
  volume   = {109},
  number   = {1},
  pages    = {171-202},
  abstract = {Statistical agencies face a dual mandate to publish accurate statistics while protecting respondent privacy. Increasing privacy protection requires decreased accuracy. Recognizing this as a resource allocation problem, we propose an economic solution: operate where the marginal cost of increasing privacy equals the marginal benefit. Our model of production, from computer science, assumes data are published using an efficient differentially private algorithm. Optimal choice weighs the demand for accurate statistics against the demand for privacy. Examples from U.S.\ statistical programs show how our framework can guide decision-making. Further progress requires a better understanding of willingness-to-pay for privacy and statistical accuracy.},
  keywords = {Economics of Privacy, Formal Privacy, Statistical Disclosure Limitation, primary, background},
}

@Article{acquisti:taylor:wagman:2015,
  author    = {Acquisti, Alessandro and Taylor, Curtis and Wagman, Liad},
  title     = {The Economics of Privacy},
  journal   = {Journal of Economic Literature},
  year      = {2016},
  volume    = {54},
  number    = {2},
  pages     = {442--492},
  month     = jun,
  doi       = {10.1257/jel.54.2.442},
  keywords  = {Economics of Privacy, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {http://www.aeaweb.org/articles?id=10.1257/jel.54.2.442},
}

@Article{anderson:challenges:JOS:2007,
  author    = {Anderson, Margo and Seltzer, William},
  title     = {Challenges to the confidentiality of {US} federal statistics, 1910-1965},
  journal   = {Journal of Official Statistics},
  year      = {2007},
  volume    = {23},
  number    = {1},
  pages     = {1},
  keywords  = {Statistical Disclosure Limitation, SDL, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
}

@Article{10.1257/aer.20161079,
  author   = {Bergemann, Dirk and Bonatti, Alessandro and Smolin, Alex},
  title    = {The Design and Price of Information},
  journal  = {American Economic Review},
  year     = {2018},
  volume   = {108},
  number   = {1},
  pages    = {1-48},
  month    = {January},
  doi      = {10.1257/aer.20161079},
  keywords = {data unions, value of data, primary},
  url      = {http://www.aeaweb.org/articles?id=10.1257/aer.20161079},
}

@Article{BrennerNissim:Impossibility:SIAM:2014,
  author   = {Hai Brenner and Kobbi Nissim},
  title    = {Impossibility of Differentially Private Universally Optimal Mechanisms},
  journal  = {SIAM Journal on Computing},
  year     = {2014},
  volume   = {43},
  number   = {5},
  pages    = {1513-1540},
  doi      = {10.1137/110846671},
  eprint   = {https://doi.org/10.1137/110846671},
  keywords = {Formal Privacy, primary},
  url      = {
        https://doi.org/10.1137/110846671
},
}

@Article{Campbell:Privacy:JEMS:,
  author   = {Campbell, James and Goldfarb, Avi and Tucker, Catherine},
  title    = {Privacy Regulation and Market Structure},
  journal  = {Journal of Economics \& Management Strategy},
  year     = {2015},
  volume   = {24},
  number   = {1},
  pages    = {47-73},
  abstract = {This paper models how regulatory attempts to protect the privacy of consumers' data affect the competitive structure of data-intensive industries. Our results suggest that the commonly used consent-based approach may disproportionately benefit firms that offer a larger scope of services. Therefore, though privacy regulation imposes costs on all firms, it is small firms and new firms that are most adversely affected. We then show that this negative effect will be particularly severe for goods where the price mechanism does not mediate the effect, such as the advertising-supported Internet.},
  doi      = {10.1111/jems.12079},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/jems.12079},
  keywords = {economics of privacy, primary},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jems.12079},
}

@Article{CardAER2012,
  author   = {Card, David and Mas, Alexandre and Moretti, Enrico and Saez, Emmanuel},
  title    = {Inequality at work: the effect of peer salaries on job satisfaction},
  journal  = {American Economic Review},
  year     = {2012},
  volume   = {102},
  number   = {6},
  pages    = {2981--3003},
  month    = may,
  doi      = {10.1257/aer.102.6.2981},
  keywords = {value of data, primary},
  url      = {http://www.aeaweb.org/articles?id=10.1257/aer.102.6.2981},
}

@Article{Childs:Confidence:SP:2015,
  author    = {Jennifer Hunter Childs and Ryan King and Aleia Fobia},
  title     = {Confidence in {U.S.} federal statistical agencies},
  journal   = {Survey Practice},
  year      = {2015},
  volume    = {8},
  number    = {5},
  issn      = {2168-0094},
  abstract  = {At a time when public confidence in the Federal government is at an all-time low, Federal statistical agencies were interested in knowing whether their image would suffer as well. Using data gathered in the Gallup Daily Poll to answer this question, we found that, as level of knowledge about federal statistics increases and for data users, respondents' discrimination among government entities seems to increase -- the strength of the relationships between confidence in the Federal Statistical System, on one hand, and in Congress and the Military, on the other, decreases. In a time when confidence in Congress is particularly poor, increasing knowledge about the statistical system and increasing the public's use of statistical data, through programs like "Statistics in Schools" could help people differentiate between sectors of the government, thus increasing confidence in the Federal Statistical System.},
  doi       = {10.29115/sp-2015-0024},
  keywords  = {Confidence in Institutions; Trust in Government; Trust in Official Statistics, official statistics, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {https://www.surveypractice.org/article/2833-confidence-in-u-s-federal-statistical-agencies},
}

@Misc{title13,
  author       = {{13 U.S.~Code}},
  title        = {{USC}: Title 13 - {Census Act}},
  year         = {1954},
  keywords     = {policy, background},
  lastaccessed = {February 11, 2013},
  owner        = {vilhuber},
  timestamp    = {2016.08.30},
  url          = {\url{https://www.law.cornell.edu/uscode/pdf/lii_usc_TI_13.pdf}},
}

@Misc{cipsea,
  author       = {{44 U.S.~Code}},
  title        = {{C}onfidential {I}nformation {P}rotection and {S}tatistical {E}fficency {A}ct},
  year         = {2002},
  note         = {Pub. L. 107-347, title V, Dec. 17, 2002, 116 Stat. 2962 ( 44 U.S.C. 3501 note)},
  keywords     = {policy, background},
  lastaccessed = {February 11, 2013},
  owner        = {vilhuber},
  timestamp    = {2016.08.30},
  url          = {\url{http://www.law.cornell.edu/topn/confidential_information_protection_and_statistical_efficiency_act_of_2002}},
}

@Misc{commerce.gov_2018,
  author       = {{U.S.~Department of Commerce}},
  title        = {{U.S.\ Department of Commerce Announces Reinstatement of Citizenship Question to the 2020 Decennial Census}},
  howpublished = {\url{https://www.commerce.gov/news/press-releases/2018/03/us-department-commerce-announces-reinstatement-citizenship-question-2020}},
  month        = {3},
  year         = {2018},
  note         = {Accessed: March 13, 2018},
  keywords     = {policy, primary},
}

@Article{couper2008risk,
  author    = {Couper, Mick P and Singer, Eleanor and Conrad, Frederick G and Groves, Robert M},
  title     = {Risk of disclosure, perceptions of risk, and concerns about privacy and confidentiality as factors in survey participation},
  journal   = {Journal of official statistics},
  year      = {2008},
  volume    = {24},
  number    = {2},
  pages     = {255},
  keywords  = {value of privacy, primary},
  publisher = {NIH Public Access},
}

@Article{cummings:empirical:corr:2014,
  author    = {Rachel Cummings and Federico Echenique and Adam Wierman},
  title     = {The Empirical Implications of Privacy-Aware Choice},
  journal   = {CoRR},
  year      = {2014},
  volume    = {abs/1401.0336},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  keywords  = {formal privacy, primary},
  timestamp = {Sun, 02 Feb 2014 18:37:28 +0100},
  url       = {http://arxiv.org/abs/1401.0336},
  xbiburl   = {http://dblp.uni-trier.de/rec/bib/journals/corr/CummingsEW14},
}

@Article{cummings:adaptive:corr:2016,
  author    = {Rachel Cummings and Katrina Ligett and Kobbi Nissim and Aaron Roth and Zhiwei Steven Wu},
  title     = {Adaptive Learning with Robust Generalization Guarantees},
  journal   = {CoRR},
  year      = {2016},
  volume    = {abs/1602.07726},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  doi       = {N/A},
  keywords  = {value of privacy, primary},
  timestamp = {Tue, 01 Mar 2016 17:47:25 +0100},
  url       = {http://arxiv.org/abs/1602.07726},
  xbiburl   = {http://dblp.uni-trier.de/rec/bib/journals/corr/CummingsLNRW16},
}

@Article{Dalenius:Towards:1977,
  author    = {Dalenius, Tore},
  title     = {Towards a methodology for statistical disclosure control},
  journal   = {Statistik Tidskrift},
  year      = {1977},
  volume    = {15},
  pages     = {429--444},
  doi       = {10.1145/320613.320616},
  keywords  = {statistical disclosure limitation, SDL, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {https://dl.acm.org/citation.cfm?doid=320613.320616},
  xurlx     = {http://dx.doi.org/10.1145/320613.320616},
}

@InProceedings{Dinur:2003:RIW:773153.773173,
  author    = {Dinur, Irit and Nissim, Kobbi},
  title     = {Revealing information while preserving privacy},
  booktitle = {Proceedings of the Twenty-second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
  year      = {2003},
  series    = {PODS '03},
  pages     = {202--210},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {773173},
  doi       = {10.1145/773153.773173},
  isbn      = {1-58113-670-6},
  keywords  = {data reconstruction, integrity and security, subset-sums with noise, formal privacy, primary},
  location  = {San Diego, California},
  numpages  = {9},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {http://doi.acm.org/10.1145/773153.773173},
}

@InProceedings{Duchi:Minimax:IEEE:2013,
  author    = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright},
  title     = {Local Privacy and Statistical Minimax Rates},
  booktitle = {Proceedings of the 2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
  year      = {2013},
  series    = {FOCS '13},
  pages     = {429--438},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {2570612},
  doi       = {10.1109/FOCS.2013.53},
  isbn      = {978-0-7695-5135-7},
  keywords  = {Differential privacy, minimax rates, estimation, formal privacy, primary},
  numpages  = {10},
  url       = {http://dx.doi.org/10.1109/FOCS.2013.53},
}

@Article{Duncan:Lambert:1986,
  author    = {George Duncan and Diane Lambert},
  title     = {Disclosure-limited data dissemination},
  journal   = {Journal of the American Statistical Association},
  year      = {1986},
  volume    = {81},
  number    = {393},
  pages     = {10--18},
  month     = {3},
  doi       = {10.1080/01621459.1986.10478229},
  keywords  = {statistical disclosure limitation, SDL, primary},
  owner     = {John Abowd},
  timestamp = {2014.12.19},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1986.10478229},
}

@InCollection{Dwork:Generalization:NIPS:2015,
  author    = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toni and Reingold, Omer and Roth, Aaron},
  title     = {Generalization in Adaptive Data Analysis and Holdout Reuse},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {Curran Associates, Inc.},
  year      = {2015},
  editor    = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
  pages     = {2341--2349},
  doi       = {N/A},
  keywords  = {value of privacy, primary},
  url       = {http://papers.nips.cc/paper/5993-generalization-in-adaptive-data-analysis-and-holdout-reuse.pdf},
}

@InProceedings{Dworketal:2006,
  author    = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  title     = {{Calibrating Noise to Sensitivity in Private Data Analysis}},
  booktitle = {Proceedings of the Third conference on Theory of Cryptography},
  year      = {2006},
  series    = {TCC'06},
  pages     = {265--284},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  note      = {DOI:10.1007/11681878{\_}14},
  acmid     = {2180305},
  doi       = {10.29012/jpc.v7i3.405},
  isbn      = {978-3-540-32731-8},
  keywords  = {formal privacy, primary},
  location  = {New York, NY},
  numpages  = {20},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {https://link.springer.com/chapter/10.1007%2F11681878_14},
}

@Article{Dwork:Roth:journal:version:2014,
  author    = {Dwork, Cynthia and Roth, Aaron},
  title     = {{The Algorithmic Foundations of Differential Privacy}},
  journal   = {Foundations and Trends in Theoretical Computer Science},
  year      = {2014},
  volume    = {9},
  number    = {3-4},
  pages     = {211--407},
  issn      = {1551-305X},
  doi       = {10.1561/0400000042},
  keywords  = {formal privacy, background},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-042},
}

@Article{Fellegi:1972,
  author    = {Fellegi, I. P.},
  title     = {On the question of statistical confidentiality},
  journal   = {Journal of the American Statistical Association},
  year      = {1972},
  volume    = {67},
  number    = {337},
  pages     = {7--18},
  issn      = {0162-1459},
  abstract  = {In Section 1 the nature of statistical confidentiality is explored, i.e., its essential role in the collection of data by statistical offices, its relationship to privacy and the need for increased attention to potential statistical disclosures because of the increased tabulation and dissemination capabilities of statistical offices. In Section 2 a definition of inadvertent direct disclosure is provided as well as a theorem concerning a test for residual disclosure of tabulations. In Section 3 different media and methods of data dissemination are considered from the point of view of potential for statistical disclosure.},
  copyright = {Copyright 1972 American Statistical Association},
  doi       = {10.2307/2284695},
  keywords  = {statistical disclosure limiation, SDL, primary},
  language  = {English},
  owner     = {vilhuber},
  publisher = {American Statistical Association},
  timestamp = {2016.08.30},
  url       = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1972.10481199#.XFuE8VxKg2w},
  xurlx     = {http://www.jstor.org/stable/2284695},
}

@TechReport{Garfinkel:Deidentification:NIST:2015,
  author      = {Simson Garfinkel},
  title       = {De-{I}dentification of Personal Information},
  institution = {National Institute of Standards and Technology},
  year        = {2015},
  type        = {Internal Report},
  number      = {8053},
  month       = {10},
  doi         = {10.6028/nist.ir.8053},
  keywords    = {statistical disclosure limitation, SDL, primary},
  series      = {Internal Report},
  url         = {http://costic1206.uvigo.es/sites/default/files/Documents_of_Interest/NISTIR%208053.pdf},
}

@Article{Ghosh:Auction:GEB:2015,
  author   = {Arpita Ghosh and Aaron Roth},
  title    = {Selling privacy at auction},
  journal  = {Games and Economic Behavior},
  year     = {2015},
  volume   = {91},
  pages    = {334--346},
  doi      = {10.1016/j.geb.2013.06.013},
  keywords = {value of privacy, primary},
  url      = {https://www.sciencedirect.com/science/article/pii/S0899825613000961},
}

@InProceedings{ghosh:utility:ACM:2009:,
  author    = {Ghosh, Arpita and Roughgarden, Tim and Sundararajan, Mukund},
  title     = {Universally Utility-maximizing Privacy Mechanisms},
  booktitle = {Proceedings of the Forty-first Annual ACM Symposium on Theory of Computing},
  year      = {2009},
  series    = {STOC '09},
  pages     = {351--360},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1536464},
  doi       = {10.1145/1536414.1536464},
  isbn      = {978-1-60558-506-2},
  keywords  = {differential privacy, linear programming, privacy, utility, primary},
  location  = {Bethesda, MD, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1536414.1536464},
}

@Article{Goldfarb:Shifts:AERPP:2012,
  author   = {Goldfarb, Avi and Tucker, Catherine},
  title    = {Shifts in Privacy Concerns},
  journal  = {American Economic Review},
  year     = {2012},
  volume   = {102},
  number   = {3},
  pages    = {349-53},
  month    = {May},
  doi      = {10.1257/aer.102.3.349},
  keywords = {economics; privacy; economics of privacy; measurement; privacy measurement, value of privacy, primary},
  url      = {http://www.aeaweb.org/articles?id=10.1257/aer.102.3.349},
}

@Article{Goroff2015,
  author    = {Goroff, Daniel L.},
  title     = {{Balancing privacy versus accuracy in research protocols}},
  journal   = {Science},
  year      = {2015},
  volume    = {347},
  number    = {6221},
  pages     = {479--480},
  abstract  = {Designing protocols for research using personal data entails trade-offs between accuracy and privacy. Any suggestion that would make empirical work less precise, open, representative, or replicable seems contrary to the needs and values of science. A careful reexamination has begun of what accuracy? or privacy? should mean and how research plans can balance these objectives.},
  doi       = {10.1126/science.aaa3483},
  eprint    = {http://www.sciencemag.org/content/347/6221/479.full.pdf},
  keywords  = {value of privacy, primary},
  owner     = {vilhuber},
  pmid      = {25635075},
  timestamp = {2016.08.30},
  url       = {http://www.sciencemag.org/content/347/6221/479$\backslash$nhttp://www.ncbi.nlm.nih.gov/pubmed/25635075$\backslash$nhttp://www.sciencemag.org/content/347/6221/479.full.pdf$\backslash$nhttp://www.sciencemag.org/content/347/6221/479.summary},
}

@InProceedings{Gupta:2012:ICP:2238936.2238961,
  author    = {Gupta, Anupam and Roth, Aaron and Ullman, Jonathan},
  title     = {Iterative constructions and private data release},
  booktitle = {Proceedings of the 9th International Conference on Theory of Cryptography},
  year      = {2012},
  series    = {TCC'12},
  pages     = {339--356},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid     = {2238961},
  doi       = {10.1007/978-3-642-28914-9_19},
  isbn      = {978-3-642-28913-2},
  keywords  = {formal privacy, primary},
  location  = {Sicily, Italy},
  numpages  = {18},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {https://link.springer.com/chapter/10.1007%2F978-3-642-28914-9_19},
  xurlx     = {http://dx.doi.org/10.1007/978-3-642-28914-9_19},
}

@InCollection{HaneySIGMOD2017,
  author    = {Samuel Haney and Ashwin Machanavajjhala and John M. Abowd and Matthew Graham and Mark Kutzbach and Lars Vilhuber},
  title     = {Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics},
  booktitle = {Proceedings of the 2017 International Conference on Management of Data},
  publisher = {ACM},
  year      = {2017},
  volume    = {forthcoming},
  series    = {SIGMOD '17},
  abstract  = {National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures.
	In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter $\epsilon\geq$ 1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional SDL algorithms. Those queries are fodder for future research.},
  acmid     = {3035940},
  doi       = {10.1145/3035918.3035940},
  journal   = {SIGMOD},
  keywords  = {official statistics, primary},
  owner     = {vilhuber},
  timestamp = {2017.03.01},
  url       = {http://dx.doi.org/10.1145/3035918.3035940},
}

@InCollection{Hardt:Simple:NIPS:2012,
  author    = {Hardt, Moritz and Katrina Ligett and Frank Mc{S}herry},
  title     = {{A Simple and Practical Algorithm for Differentially Private Data Release.}},
  booktitle = {Advances in Neural Information Processing Systems 25},
  publisher = {Curran Associates, Inc.},
  year      = {2012},
  editor    = {F. Pereira and C.J.C. Burges and L. Bottou and K.Q. Weinberger},
  pages     = {2339--2347},
  abstract  = {We present new theoretical results on differentially private data release useful with respect to any target class of counting queries, coupled with experimental results on a variety of real world data sets. Specifically, we study a simple combination of the multiplicative weights approach of [Hardt and Rothblum, 2010] with the exponential mechanism of [McSherry and Talwar, 2007]. The multiplicative weights framework allows us to maintain and improve a distribution approximating a given data set with respect to a set of counting queries. We use the exponential mechanism to select those queries most incorrectly tracked by the current distribution. Combing the two, we quickly approach a distribution that agrees with the data set on the given set of queries up to small error. The resulting algorithm and its analysis is simple, but nevertheless improves upon previous work in terms of both error and running time. We also empirically demonstrate the practicality of our approach on several data sets commonly used in the statistical community for contingency table release.},
  keywords  = {formal privacy, primary},
  owner     = {vilhuber},
  timestamp = {2017.12.22},
  url       = {http://papers.nips.cc/paper/4548-a-simple-and-practical-algorithm-for-differentially-private-data-release.pdf},
}

@Article{Hardt:Multiplicative:FOCS10,
  author    = {Hardt, Moritz and Rothblum, Guy N.},
  title     = {A Multiplicative Weights Mechanism for Privacy-Preserving Data Analysis},
  journal   = {2010 IEEE 51st Annual Symposium on Foundations of Computer Science},
  year      = {2010},
  pages     = {61--70},
  issn      = {0272-5428},
  abstract  = {We consider statistical data analysis in the interactive setting. In this setting a trusted curator maintains a database of sensitive information about individual participants, and releases privacy-preserving answers to queries as they arrive. Our primary contribution is a new differentially private multiplicative weights mechanism for answering a large number of interactive counting (or linear) queries that arrive online and may be adaptively chosen. This is the first mechanism with worst-case accuracy guarantees that can answer large numbers of interactive queries and is efficient (in terms of the runtime's dependence on the data universe size). The error is asymptotically optimal in its dependence on the number of participants, and depends only logarithmically on the number of queries being answered. The running time is nearly linear in the size of the data universe. As a further contribution, when we relax the utility requirement and require accuracy only for databases drawn from a rich class of databases, we obtain exponential improvements in running time. Even in this relaxed setting we continue to guarantee privacy for any input database. Only the utility requirement is relaxed. Specifically, we show that when the input database is drawn from a smooth distribution - a distribution that does not place too much weight on any single data item - accuracy remains as above, and the running time becomes poly-logarithmic in the data universe size. The main technical contributions are the application of multiplicative weights techniques to the differential privacy setting, a new privacy analysis for the interactive setting, and a technique for reducing data dimensionality for databases drawn from smooth distributions.},
  address   = {Los Alamitos, CA, USA},
  doi       = {10.1109/FOCS.2010.85},
  isbn      = {978-1-4244-8525-3},
  keywords  = {data dimensionality reduction,data universe,differ, formal privacy, primary},
  owner     = {vilhuber},
  publisher = {IEEE Computer Society},
  timestamp = {2016.08.30},
  url       = {https://ieeexplore.ieee.org/document/5670948},
}

@TechReport{spwp22,
  author      = {Harris-Kojetin, Brian A. and Alvey, Wendy L. and Carlson, Lynda and Cohen, Steven B. and Cohen, Steve H. and Cox, Lawrence H. and Fay, Robert E. and Fecso, Ronald and Fixler, Dennis and Gates, Gerald and Graubard, Barry and Iwig, William and Kennickell, Arthur and Kirkendall, Nancy J. and Schechter, Susan and Schmitt, Rolf R. and Seastrom, Marilyn and Sirken, Monroe G. and Spruill, Nancy L. and Tucker, Clyde and Tupek, Alan R. and Williamson,G. David and Groves, Robert},
  title       = {Statistical Policy Working Paper 22: Report on Statistical Disclosure Limitation Methodology},
  institution = {U.S. Federal Committee on Statistical Methodology},
  year        = {2005},
  type        = {Research Report},
  month       = {12},
  keywords    = {statistical disclosure limitation, SDL, primary},
  owner       = {Cameron},
  timestamp   = {2015.02.05},
}

@InBook{He:Blowfish:ACMSIGMOD:2014,
  pages     = {1447--1458},
  title     = {Blowfish privacy: tuning privacy-utility trade-offs using policies},
  publisher = {Association for Computing Machinery},
  year      = {2014},
  author    = {Xi He and Ashwin Machanavajjhala and Bolin Ding},
  isbn      = {9781450323765},
  booktitle = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
  doi       = {10.1145/2588555.2588581},
  keywords  = {Blowfish privacy, Differential privacy, Privacy, formal privacy, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {https://dl.acm.org/citation.cfm?doid=2588555.2588581},
}

@Article{Heffetz2014,
  author    = {Heffetz, Ori and Ligett, Katrina},
  title     = {Privacy and data-based research},
  journal   = {Journal of Economic Perspectives},
  year      = {2014},
  volume    = {28},
  number    = {2},
  pages     = {75--98},
  note      = {Spring},
  doi       = {10.1257/jep.28.2.75},
  keywords  = {background, primary},
  owner     = {John Abowd},
  timestamp = {2014.12.19},
  url       = {https://www.aeaweb.org/articles?id=10.1257/jep.28.2.75},
}

@Article{hirshleifer1980privacy,
  author    = {Hirshleifer, Jack},
  title     = {Privacy: its origin, function, and future},
  journal   = {The Journal of Legal Studies},
  year      = {1980},
  pages     = {649--664},
  doi       = {10.1086/467659},
  keywords  = {economics of privacy, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {https://www.journals.uchicago.edu/doi/abs/10.1086/467659?journalCode=jls},
}

@Article{Holan2010,
  author    = {Holan, Scott H. and Toth, Daniell and Ferreira, Marco {A.~R.} and Karr, Alan F.},
  title     = {Bayesian Multiscale Multiple Imputation With Implications for Data Confidentiality},
  journal   = {Journal of the American Statistical Association},
  year      = {2010},
  volume    = {105},
  number    = {490},
  pages     = {564--577},
  issn      = {0162-1459},
  abstract  = {Many scientific, sociological, and economic applications present data that are collected on multiple scales of resolution. One particular form of multiscale data arises when data are aggregated across different scales both longitudinally and by economic sector. Frequently, such datasets experience missing observations in a manner that they can be accurately imputed, while respecting the constraints imposed by the multiscale nature of the data, using the method we propose known as Bayesian multiscale multiple imputation. Our approach couples dynamic linear models with a novel imputation step based on singular normal distribution theory. Although our method is of independent interest, one important implication of such methodology is its potential effect on confidential databases protected by means of cell suppression. In order to demonstrate the proposed methodology and to assess the effectiveness of disclosure practices in longitudinal databases, we conduct a large-scale empirical study using the U.S. Bureau of Labor Statistics Quarterly Census of Employment and Wages (QCEW). During the course of our empirical investigation it is determined that several of the predicted cells are within 1{\%} accuracy, thus causing potential concerns for data confidentiality.},
  doi       = {10.1198/jasa.2009.ap08629},
  keywords  = {cell suppression,disclosure,dynamic linear models,missing data,multiscale modeling,qcew, official statistics, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2009.ap08629},
}

@Article{Hsu:EconomicEpsilon:IEEE:2014,
  author   = {Justin Hsu and Marco Gaboardi and Andreas Haeberlen and Sanjeev Khanna and Arjun Narayan and Benjamin C. Pierce and Aaron Roth},
  title    = {Differential Privacy: An Economic Method for Choosing Epsilon},
  journal  = {2014 IEEE 27th Computer Security Foundations Symposium},
  year     = {2014},
  pages    = {398--410},
  month    = jul,
  issn     = {1063-6900},
  doi      = {10.1109/CSF.2014.35},
  keywords = {data analysis;data privacy;Epsilon;data analyst;differential privacy;differentially private algorithms;economic method;privacy guarantee;Accuracy;Analytical models;Cost function;Data models;Data privacy;Databases;Privacy;Differential Privacy, economics of privacy, primary},
  url      = {https://ieeexplore.ieee.org/document/6957125},
}

@TechReport{Jin:AI-Privacy:2018:NBERw24253,
  author      = {Ginger Zhe Jin},
  title       = {Artificial Intelligence and Consumer Privacy},
  institution = {National Bureau of Economic Research},
  year        = {2018},
  type        = {Working Paper},
  number      = {24253},
  month       = {1},
  abstract    = {Thanks to big data, artificial intelligence (AI) has spurred exciting innovations. In the meantime, AI and big data are reshaping the risk in consumer privacy and data security. In this essay, I first define the nature of the problem and then present a few facts about the ongoing risk. The bulk of the essay describes how the U.S. market copes with the risk in current policy environment. It concludes with key challenges facing researchers and policy makers.},
  doi         = {10.3386/w24253},
  keywords    = {economics of privacy, primary},
  series      = {Working Paper Series},
  url         = {http://www.nber.org/papers/w24253},
}

@Misc{jones:2017,
  author       = {Christa Jones},
  title        = {Nonconfidential Memorandum on Census Bureau Privacy Breaches},
  howpublished = {Memorandum to file},
  month        = jun,
  year         = {2017},
  note         = {public document in replication archive 10.5281/zenodo.1208758},
  doi          = {N/A},
  keywords     = {background},
  url          = {N/A},
}

@InProceedings{jorgensen:personalized:ICDE:2015,
  author    = {Z. Jorgensen and T. Yu and G. Cormode},
  title     = {Conservative or liberal? Personalized differential privacy},
  booktitle = {2015 IEEE 31st International Conference on Data Engineering},
  year      = {2015},
  pages     = {1023-1034},
  month     = {4},
  abstract  = {Differential privacy is widely accepted as a powerful framework for providing strong, formal privacy guarantees for aggregate data analysis. A limitation of the model is that the same level of privacy protection is afforded for all individuals. However, it is common that the data subjects have quite different expectations regarding the acceptable level of privacy for their data. Consequently, differential privacy may lead to insufficient privacy protection for some users, while over-protecting others. We argue that by accepting that not all users require the same level of privacy, a higher level of utility can often be attained by not providing excess privacy to those who do not want it. We propose a new privacy definition called personalized differential privacy (PDP), a generalization of differential privacy in which users specify a personal privacy requirement for their data. We then introduce several novel mechanisms for achieving PDP. Our primary mechanism is a general one that automatically converts any existing differentially private algorithm into one that satisfies PDP. We also present a more direct approach for achieving PDP, inspired by the well-known exponential mechanism. We demonstrate our framework through extensive experiments on real and synthetic data.},
  doi       = {10.1109/ICDE.2015.7113353},
  issn      = {1063-6382},
  keywords  = {data protection;PDP;aggregate data analysis;exponential mechanism;formal privacy guarantees;personalized differential privacy;primary mechanism;privacy level;privacy protection;real data;synthetic data;utility level;Lead;Privacy, formal privacy},
  url       = {https://ieeexplore.ieee.org/document/7113353},
}

@Article{kasiviswanathan2014semantics,
  author   = {Kasiviswanathan, Shiva P and Smith, Adam},
  title    = {On the 'Semantics' of Differential Privacy: A Bayesian Formulation},
  journal  = {Journal of Privacy and Confidentiality},
  year     = {2014},
  volume   = {6},
  number   = {1},
  pages    = {1},
  doi      = {10.29012/jpc.v6i1.634},
  keywords = {formal privacy, primary},
  url      = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/634},
}

@Article{KinneyEtAl2011,
  author    = {Kinney, Satkartar K. and Reiter, Jerome P. and Reznek, Arnold P. and Miranda, Javier and Jarmin, Ron S. and Abowd, John M.},
  title     = {Towards Unrestricted Public Use Business Microdata: The {Synthetic} {Longitudinal} {Business} {Database}},
  journal   = {International Statistical Review},
  year      = {2011},
  volume    = {79},
  number    = {3},
  pages     = {362--384},
  issn      = {1751-5823},
  abstract  = {In most countries, national statistical agencies do not release establishment-level business microdata, because doing so represents too large a risk to establishments' confidentiality. One approach with the potential for overcoming these risks is to release synthetic data; that is, the released establishment data are simulated from statistical models designed to mimic the distributions of the underlying real microdata. In this article, we describe an application of this strategy to create a public use file for the Longitudinal Business Database, an annual economic census of establishments in the United States comprising more than 20 million records dating back to 1976. The U.S. Bureau of the Census and the Internal Revenue Service recently approved the release of these synthetic microdata for public use, making the synthetic Longitudinal Business Database the first-ever business microdata set publicly released in the United States. We describe how we created the synthetic data, evaluated analytical validity, and assessed disclosure risk.},
  doi       = {10.1111/j.1751-5823.2011.00153.x},
  keywords  = {Economic census, data confidentiality, synthetic data, disclosure limitation, statistical disclosure limitation, SDL, primary},
  owner     = {vilhuber},
  publisher = {Blackwell Publishing Ltd},
  timestamp = {2012.09.04},
  url       = {http://dx.doi.org/10.1111/j.1751-5823.2011.00153.x},
}

@Misc{Harvard:DataPrivacyLab,
  author       = {{Harvard Data Privacy Lab}},
  title        = {{Harvard Data Privacy Lab Homepage}},
  howpublished = {\url{https://dataprivacylab.org/}},
  year         = {2018},
  note         = {Accessed: 2018-03-17},
  doi          = {N/A},
  keywords     = {background},
  url          = {https://dataprivacylab.org/},
}

@Article{Li2014,
  author        = {Li, Chao and Li, Daniel Yang and Miklau, Gerome and Suciu, D A N},
  title         = {{A Theory of Pricing Private Data}},
  journal       = {ACM Transactions on Database Systems},
  year          = {2014},
  volume        = {39},
  number        = {4},
  pages         = {34:1--34:27},
  issn          = {0362-5915},
  note          = {Pages 34:1--34:27},
  archiveprefix = {arXiv},
  arxivid       = {1208.5258},
  doi           = {10.1145/2448496.2448502},
  eprint        = {1208.5258},
  isbn          = {9781450315982},
  keywords      = {arbitrage,data pricing,differential privacy, value of privacy, primary},
  owner         = {vilhuber},
  timestamp     = {2016.08.30},
  url           = {https://dl.acm.org/citation.cfm?doid=2448496.2448502},
}

@Article{li:matrix:VLDB:2015,
  author   = {Li, Chao and Miklau, Gerome and Hay, Michael and McGregor, Andrew and Rastogi, Vibhor},
  title    = {The matrix mechanism: optimizing linear counting queries under differential privacy},
  journal  = {The VLDB Journal},
  year     = {2015},
  volume   = {24},
  number   = {6},
  pages    = {757--781},
  issn     = {0949-877X},
  abstract = {Differential privacy is a robust privacy standard that has been successfully applied to a range of data analysis tasks. We describe the matrix mechanism, an algorithm for answering a workload of linear counting queries that adapts the noise distribution to properties of the provided queries. Given a workload, the mechanism uses a different set of queries, called a query strategy, which are answered using a standard Laplace or Gaussian mechanism. Noisy answers to the workload queries are then derived from the noisy answers to the strategy queries. This two-stage process can result in a more complex, correlated noise distribution that preserves differential privacy but increases accuracy. We provide a formal analysis of the error of query answers produced by the mechanism and investigate the problem of computing the optimal query strategy in support of a given workload. We show that this problem can be formulated as a rank-constrained semidefinite program. We analyze two seemingly distinct techniques proposed in the literature, whose similar behavior is explained by viewing them as instances of the matrix mechanism. We also describe an extension of the mechanism in which nonnegativity constraints are included in the derivation process and provide experimental evidence of its efficacy.},
  doi      = {10.1007/s00778-015-0398-x},
  keywords = {formal privacy, primary},
  url      = {http://dx.doi.org/10.1007/s00778-015-0398-x},
}

@InProceedings{Machanavajjhala:OTM:ICDE:2008,
  author    = {Machanavajjhala, A. and Kifer, D. and Abowd, J. and Gehrke, J. and Vilhuber, L.},
  title     = {Privacy: theory meets practice on the map},
  booktitle = {Proceedings of the 2008 IEEE 24th International Conference on Data Engineering},
  year      = {2008},
  pages     = {277--286},
  month     = apr,
  abstract  = {In this paper, we propose the first formal privacy analysis of a data anonymization process known as the synthetic data generation, a technique becoming popular in the statistics community. The target application for this work is a mapping program that shows the commuting patterns of the population of the United States. The source data for this application were collected by the U.S. Census Bureau, but due to privacy constraints, they cannot be used directly by the mapping program. Instead, we generate synthetic data that statistically mimic the original data while providing privacy guarantees. We use these synthetic data as a surrogate for the original data. We find that while some existing definitions of privacy are inapplicable to our target application, others are too conservative and render the synthetic data useless since they guard against privacy breaches that are very unlikely. Moreover, the data in our target application is sparse, and none of the existing solutions are tailored to anonymize sparse data. In this paper, we propose solutions to address the above issues.},
  doi       = {10.1109/ICDE.2008.4497436},
  keywords  = {Computer science;Data analysis;Data privacy;Law;Legal factors;Statistical analysis;data handling;data privacy;statistical analysis;data anonymization process;formal privacy analysis;mapping program;statistical inference;synthetic data generation; background, primary},
  owner     = {vilhuber},
  timestamp = {2017.06.27},
}

@Article{Manski2014,
  author   = {Manski, Charles F.},
  title    = {Communicating Uncertainty in Official Economic Statistics: An Appraisal Fifty Years after Morgenstern},
  journal  = {Journal of Economic Literature},
  year     = {2015},
  volume   = {53},
  number   = {3},
  pages    = {631-53},
  month    = {9},
  doi      = {10.1257/jel.53.3.631},
  keywords = {official statistics, primary},
  url      = {https://www.aeaweb.org/articles?id=10.1257/jel.53.3.631},
  xurl     = {http://www.aeaweb.org/articles?id=10.1257/jel.53.3.631},
}

@Book{groves:harris-kojetin:2017,
  title     = {{Innovations in Federal Statistics: Combining Data Sources While Protecting Privacy}},
  publisher = {National Academies Press},
  year      = {2017},
  author    = {{National Academies of Sciences, Engineering, and Medicine}},
  series    = {Committee on National Statistics},
  address   = {Washington, DC},
  isbn      = {978-0-309-45428-5},
  doi       = {doi: 10.17226/24652},
  keywords  = {official statistics, primary},
  url       = {https://www.nap.edu/catalog/24652/innovations-in-federal-statistics-combining-data-sources-while-protecting-privacy},
}

@InProceedings{Nissim:2012:PMD:2229012.2229073,
  author    = {Nissim, Kobbi and Orlandi, Claudio and Smorodinsky, Rann},
  title     = {Privacy-aware mechanism design},
  booktitle = {Proceedings of the 13th ACM Conference on Electronic Commerce},
  year      = {2012},
  series    = {EC '12},
  pages     = {774--789},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2229073},
  doi       = {10.1145/2229012.2229073},
  isbn      = {978-1-4503-1415-2},
  keywords  = {differential privacy, mechanism design, privacy, formal privacy, primary},
  location  = {Valencia, Spain},
  numpages  = {16},
  url       = {http://doi.acm.org/10.1145/2229012.2229073},
}

@Article{Nissim:DPNonTech:WP:2018,
  author   = {Nissim, Kobbi and Steinke, Thomas and Wood, Alexandra and Altman, Micah and Bembenek, Aaron and Bun, Mark and Gaboardi, Marco and O{\textquoteright}Brien, David R. and Vadhan, Salil},
  title    = {Differential Privacy: A Primer for a Non-Technical Audience},
  journal  = {Privacy Law Scholars Conference 2017},
  year     = {2018},
  doi      = {N/A},
  keywords = {formal privacy, background},
  url      = {https://openscholar.mit.edu/sites/default/files/dept/files/nissim_et_al_-_differential_privacy_primer_for_non-technical_audiences_1.pdf},
}

@Article{Nissim2014,
  author        = {Nissim, Kobbi and Vadhan, Salil and Xiao, David},
  title         = {{Redrawing the Boundaries on Purchasing Data from Privacy-sensitive Individuals}},
  journal       = {Proceedings of the 5th Conference on Innovations in Theoretical Computer Science},
  year          = {2014},
  pages         = {411--422},
  abstract      = {We prove new positive and negative results concerning the existence of truthful and individually rational mechanisms for purchasing private data from individuals with unbounded and sensitive privacy preferences. We strengthen the impossibility results of Ghosh and Roth (EC 2011) by extending it to a much wider class of privacy valuations. In particular, these include privacy valuations that are based on ({\{}$\backslash$epsilon{\}}, {\{}$\backslash$delta{\}})-differentially private mechanisms for non-zero {\{}$\backslash$delta{\}}, ones where the privacy costs are measured in a per-database manner (rather than taking the worst case), and ones that do not depend on the payments made to players (which might not be observable to an adversary). To bypass this impossibility result, we study a natural special setting where individuals have mono- tonic privacy valuations, which captures common contexts where certain values for private data are expected to lead to higher valuations for privacy (e.g. having a particular disease). We give new mech- anisms that are individually rational for all players with monotonic privacy valuations, truthful for all players whose privacy valuations are not too large, and accurate if there are not too many players with too-large privacy valuations. We also prove matching lower bounds showing that in some respects our mechanism cannot be improved significantly.},
  archiveprefix = {arXiv},
  arxivid       = {1401.4092},
  doi           = {10.1145/2554797.2554835},
  eprint        = {1401.4092},
  isbn          = {978-1-4503-2698-8},
  keywords      = {differential privacy,mechanism design, value of privacy, primary},
  owner         = {vilhuber},
  timestamp     = {2016.08.30},
  url           = {http://doi.acm.org/10.1145/2554797.2554835},
}

@Article{Ohm:Broken:UCLALR:2010,
  author   = {Ohm, Paul},
  title    = {Broken promises of privacy: responding to the surprising failure of anonymization},
  journal  = {UCLA Law Review},
  year     = {2010},
  volume   = {57},
  pages    = {1701},
  keywords = {economics of privacy, primary},
}

@Article{perez-truglia:transparency:SSRN:2016,
  author   = {Ricardo Perez-Truglia},
  title    = {The effects of income transparency on well-being: evidence from a natural experiment},
  journal  = {SSRN},
  year     = {2016},
  month    = feb,
  doi      = {10.2139/ssrn.2657808},
  keywords = {value of data, primary},
  url      = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2657808},
}

@TechReport{PomattoTheCostOfInformation2018,
  author      = {Luciano Pomatto and Philipp Strack and Omer Tamuz},
  title       = {The Cost of Information},
  institution = {arXiv},
  year        = {2018},
  file        = {:E\:\\Dropbox\\DataUnions\\literature\\Pomatto_CostofInformation_arXiv_2018.pdf:PDF},
  keywords    = {value of data, primary},
}

@Article{posner1981economics,
  author    = {Posner, Richard A.},
  title     = {The economics of privacy},
  journal   = {The American economic review},
  year      = {1981},
  pages     = {405--409},
  keywords  = {economics of privacy, primary},
  owner     = {vilhuber},
  publisher = {JSTOR},
  timestamp = {2016.08.30},
}

@Article{prewitt:2011,
  author    = {Prewitt, Kenneth},
  title     = {{Why It Matters to Distinguish Between Privacy \& Confidentiality}},
  journal   = {Journal of Privacy and Confidentiality},
  year      = {2011},
  volume    = {3},
  number    = {2},
  pages     = {41-47},
  doi       = {10.29012/jpc.v3i2.600},
  keywords  = {official statistics, primary},
  owner     = {abowd},
  timestamp = {2017.04.07},
  url       = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/600},
}

@Article{samuelson:1954,
  author    = {Paul A. Samuelson},
  title     = {The pure theory of public expenditure},
  journal   = {Review of Economics and Statistics},
  year      = {1954},
  volume    = {37},
  pages     = {387--389},
  keywords  = {public goods, primary},
  owner     = {John Abowd},
  timestamp = {2015.01.09},
}

@Proceedings{Proc:NSF-Sloan:2017,
  title     = {Proceedings from the 2016 {NSF-Sloan} {Workshop on Practical Privacy}},
  year      = {2017},
  editor    = {Ian M. Schmutte and Lars Vilhuber},
  series    = {Labor Dynamics Institute},
  address   = {Cornell University},
  month     = jan,
  booktitle = {Proceedings from the 2016 {NSF-Sloan} {Workshop on Practical Privacy}},
  doi       = {N/A},
  keywords  = {official statistics, primary},
  url       = {https://digitalcommons.ilr.cornell.edu/ldi/33/},
}

@Article{Spencer:Optimal:JASA:1985,
  author   = {Bruce D. Spencer},
  title    = {Optimal Data Quality},
  journal  = {Journal of the American Statistical Association},
  year     = {1985},
  volume   = {80},
  number   = {391},
  pages    = {564-573},
  abstract = { Abstract Commonly accepted hypotheses guide practical determination of needed data quality; for example, as the probability that a decision uses data increases, the needed data quality increases, and the more rudimentary the uses of the data, the less data quality is needed. These hypotheses are formally defined and analyzed in some decision-theoretic models. Conditions under which the hypotheses hold and fail are examined. Particular attention is given to determining needed data quality when the users of the data behave nonoptimally. },
  doi      = {10.1080/01621459.1985.10478155},
  eprint   = {http://www.tandfonline.com/doi/pdf/10.1080/01621459.1985.10478155},
  keywords = {value of data, data unions, primary},
  url      = {
        http://www.tandfonline.com/doi/abs/10.1080/01621459.1985.10478155

},
}

@Article{Seeskin:Spencer:Effects:2015,
  author   = {Spencer, {Bruce David} and Seeskin, {Zachary H.}},
  title    = {Effects of Census Accuracy on Apportionment of Congress and Allocations of Federal Funds},
  journal  = {JSM Proceedings, Government Statistics Section},
  year     = {2015},
  pages    = {3061--3075},
  doi      = {N/A},
  keywords = {value of data, primary},
  language = {English (US)},
  url      = {https://www.ipr.northwestern.edu/publications/papers/2015/ipr-wp-15-05.html},
}

@Article{stigler1980introduction,
  author    = {Stigler, George J.},
  title     = {An introduction to privacy in economics and politics},
  journal   = {Journal of Legal Studies},
  year      = {1980},
  volume    = {9},
  number    = {4},
  pages     = {623--644},
  month     = {12},
  issn      = {0047-2530},
  abstract  = {The enormous increase in interest in privacy in our society is evident in the public press and in the statute books. In some respects this interest in privacy is paradoxical, for the average citizen has more privacy-more areas of his life in which his behavior is not known by his fellows-than ever before. He lives in a large city, where no one is his keeper; in the small towns of former times privacy was won only by the cleverest people. He works in large organizations, and indeed he (or, more likely, some self-appointed spokesman) laments his alienation. He can shake off most of his past simply by moving-to the South, the West-and no earlier generation except the immigrant waves before World War I was as mobile.},
  doi       = {10.2307/724174},
  keywords  = {economics of privacy, primary},
  owner     = {vilhuber},
  timestamp = {2016.09.01},
}

@Article{sweeney:2002,
  author    = {L Sweeney},
  title     = {Achieving k-anonymity privacy protection using generalization and suppression},
  journal   = {International Journal on Uncertainty, Fuzziness and Knowledge-based Systems},
  year      = {2002},
  volume    = {10},
  number    = {5},
  pages     = {571--588},
  doi       = {10.1142/s021848850200165x},
  keywords  = {formal privacy, primary},
  owner     = {John Abowd},
  timestamp = {2014.12.19},
}

@Article{Taylor:Consumer:RAND:2004,
  author    = {Taylor, Curtis R.},
  title     = {Consumer privacy and the market for customer information},
  journal   = {The RAND Journal of Economics},
  year      = {2004},
  volume    = {35},
  number    = {4},
  pages     = {631--650},
  issn      = {0741-6261},
  abstract  = {I investigate consumer privacy and the market for customer information in electronic retailing. The value of customer information derives from the ability of Internet firms to identify individual consumers and charge them personalized prices. I study two settings, a confidential regime in which the sale of customer information is not possible, and a disclosure regime in which one firm may compile and sell a customer list to another firm that uses it to price discriminate. Welfare comparisons depend critically on whether consumers anticipate sale of the list and on demand elasticity.},
  copyright = {Copyright 2004 RAND Corporation},
  doi       = {10.2307/1593765},
  keywords  = {value of data, data union, primary},
  language  = {English},
  owner     = {vilhuber},
  publisher = {Wiley on behalf of RAND Corporation},
  timestamp = {2016.08.30},
  url       = {http://doi.wiley.com/10.2307/1593765},
  xurlx     = {http://www.jstor.org/stable/1593765},
}

@Article{Varian1996,
  author    = {Varian, Hal},
  title     = {{Economic aspects of personal privacy}},
  journal   = {Topics in Regulatory Economics and Policy},
  year      = {1996},
  number    = {3},
  pages     = {1--12},
  abstract  = {The advent of low-cost technology for manipulating and communicating information has raised significant concerns about personal privacy. Privacy is a complex issue and can be treated from many perspectives; this whitepaper provides an overview of some of the economic issues surrounding privacy.2 In particular, I first describe the role of privacy in economic transactions and argue that consumers will rationally want certain kinds of information about themselves to be available to producers and want other kinds of information to be secret. I then go on to consider how one might define property rights in private information in ways that allow consumers to retain control over how information about them is used.},
  doi       = {10.1007/978-1-4419-0038-8},
  isbn      = {9781441900388},
  keywords  = {economics of privacy, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.1701{\&}amp;rep=rep1{\&}amp;type=pdf$\backslash$nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.1701{\&}rep=rep1{\&}type=pdf},
}

@Article{Varian1998,
  author    = {Varian, Hal R},
  title     = {{Markets for Information Goods}},
  journal   = {October},
  year      = {1998},
  volume    = {1998},
  number    = {4},
  pages     = {1--19},
  abstract  = {Much has been written about the difficulties that ``information'' poses for neoclassical economics. How ironic that ICE-information, communication, and entertainment-now comprises the largest sector in the American economy. If information poses problems for economic theory, so much the worse for economic theory: real markets seem to deal with information rather well. This paradox is the central theme of this essay: information, that slippery and strange economic good, is, in fact, handled very well by market institutions. The reason is that real markets are much more creative than those simple competitive markets studied in Econ 1. The fact that real-life markets can handle a good as problematic as is a testament to the flexibility and robustness of market institutions.},
  keywords  = {value of data, primary},
  owner     = {vilhuber},
  timestamp = {2016.08.30},
  url       = {http://people.ischool.berkeley.edu/{~}hal/Papers/japan/index.html},
}

@Comment{jabref-meta: databaseType:bibtex;}
