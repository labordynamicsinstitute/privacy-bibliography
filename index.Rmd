---
title: "Introductory Readings in Formal Privacy for Economists"
author: "John M. Abowd, Ian M. Schmutte, William Sexton, and Lars Vilhuber"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
site: bookdown::bookdown_site
github-repo: labordynamicsinstitute/privacy-bibliography
documentclass: article
bibliography: [primary_dynamic.bib]
link-citations: true
csl: apa.csl
references:
- id: groves:harris-kojetin:2017
  type: book
  author:
  - literal: National Academies of Sciences, Engineering, and Medicine
  issued:
  - year: 2017
  title: 'Innovations in federal statistics: Combining data sources while protecting
    privacy'
  title-short: Innovations in federal statistics
  collection-title: Committee on national statistics
  publisher: National Academies Press
  publisher-place: Washington, DC
  keyword: official statistics, primary
  URL: https://www.nap.edu/catalog/24652/innovations-in-federal-statistics-combining-data-sources-while-protecting-privacy
  DOI: 10.17226/24652
  ISBN: 978-0-309-45428-5
---
```{r create bib,echo=FALSE,include=FALSE}
source("create_primary.R",echo=TRUE)
```

# Overview
The purpose of this document is to provide scholars with a comprehensive list of readings relevant to the economic analysis of formal privacy, and particularly its application to public statistics. 
Statistical agencies and tech giants are rapidly adopting formal privacy models which make the tradeoff between privacy and data quality precise. The question then becomes, how much privacy loss should they allow? @AbowdSchmutte:Privacy:AER argue that this choice ultimately depends on how decision makers weigh the costs of privacy loss against the benefits of higher-quality data. Making progress on these questions requires familiarity with new tools from computer science and statistics, the objectives and policy environment within which statistical agencies operate, along with the economic analysis of information. 

We have organized these references into a reading course focused on 10-15 primary references in each of six different topics:

* [Formal Privacy]
* [Policy and Official Statistics]
* [Statistical Disclosure Limitation]
* [Economics of Privacy]
* [Value of Privacy and Data Accuracy]

In the remainder of this document, for each topic, we provide a very brief description of the papers in the reading course and why we selected them. In each case, we orient the reader to the key issues, concepts, and tools in each topic. `r if (knitr::is_html_output()) 'All references are repeated in the global [References] section.'` In addition to this reading course, we have also curated a much more extensive list of references, [available here](sloan-privacy-bibliography.pdf).

## Contributing
We encourage interested readers and researchers to use these readings for their classes and training, modifying it as needed. You can fork the source code at [https://github.com/labordynamicsinstitute/privacy-bibliography](https://github.com/labordynamicsinstitute/privacy-bibliography). This document is licensed under the [Creative Commons Attribution-NonCommercial 4.0 International Public License  (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/). Should that license not meet your needs, contact us to discuss possible modifications or exemption. Please send us any improvements, corrections, or other contributions, either by e-mail, or via the "[Issues](https://github.com/labordynamicsinstitute/privacy-bibliography/issues)" feature on 
Github`r if (knitr::is_html_output()) ', or by clicking on the edit button in the toolbar above'`. 

## Acknowledgements 
We gratefully acknowledge the support of Alfred P.\ [Sloan Foundation Grant G-2015-13903](https://sloan.org/grant-detail/6845) and [NSF Grant SES-1131848](http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=1131848). 

## Disclaimer
The views expressed in this paper are those of the authors and not those of the U.S. Census Bureau or other sponsors.

# Background
We start by providing a short list of background references that frame a particular set of research topics.  @AbowdSchmutte:Privacy:AER  show how to combine formal privacy models with the classic theory of public goods to understand and guide decisions about privacy protection and data dissemination. For the neophyte,  @WoodVanderbiltJ.Entertain.Technol.Law2018  provide a non-technical introduction to formal privacy models in general, and differential privacy in particular.   @Heffetz2014  also introduce differential privacy, but targeted toward economists. After reading these introductory treatments, you should review the textbook treatment of differential privacy in  @Dwork:Roth:journal:version:2014 , focusing on Chapters 1--3. We also recommend consultation of the very fine tutorial "Differential Privacy in the Wild: A tutorial on current practices and open challenges" by Michael Hay, Xi He, and Ashwin Machanavajjhala. The tutorial is available in two parts.

* Part 1: ([slides](http://sigmod2017.org/wp-content/uploads/2017/03/04-Differential-Privacy-in-the-wild-1.pdf), [video](https://www.youtube.com/watch?v=rfI-I3e_LFs)
* Part 2: ([slides](http://sigmod2017.org/wp-content/uploads/2017/03/04-Differential-Privacy-in-the-wild-2.pdf), [video](https://www.youtube.com/watch?v=Uhh7QCbnE9o)


To provide a concrete grounding in practical issues of privacy,  @jones:2017  summarizes the history of privacy breaches and privacy protection in the U.S. statistical system. It is important to ask how formal privacy models do, and do not, capture common language and legal interpretations of privacy. As such, we also recommend a review of some of the laws governing data privacy in the U.S. , e.g.  @title13  and   @cipsea  (Confidential Information Protection and Statistical Efficiency Act, also known as CIPSEA). A quick review of the Harvard Privacy Tools website  [@Harvard:PrivacyTools]  can provide a sense of how differential privacy is being implemented in various settings.  @Goroff2015  also provides a very useful overview of the key issues in this reading course for a lay audience. @Abowd:JPC:2017  and  @abowd:fcsm:2016  survey formal privacy systems being implemented at the Census Bureau.


# Formal Privacy 
The literature on formal privacy is vast. Here, we focus on those papers that will help orient the reader to the key ideas and tools of differential privacy, particularly those relevant to the economic problem of determining optimal privacy protection when publishing population statistics. For the purpose of this reading course and associated bibliography, we associate formal privacy as a literature emerging in computer science out of cryptography. In the section on "[Statistical Disclosure Limitation]", we recommend additional readings from the SDL literature, which has a distinct origin in statistics.


@Dworketal:2006 is generally regarded as the first paper to formally introduce differential privacy. Its development was due, in part, to the *database reconstruction theorem* published by @Dinur:2003:RIW:773153.773173, which showed that most data publication mechanisms are blatantly non-private in a well-defined sense. The database reconstruction theorem has recently been shown to have very practical consequences for the statistical disclosure protections in place at the Census Bureau. The concepts of *k-anonymity* [@sweeney:2002] and *l-diversity* [@Machanavajjhala:2007:LDP:1217299.1217302] are  important antecedents that bridge the formal privacy and SDL literatures.

In assessing formal privacy as a framework for modeling data publication, it is natural to consider the optimal, or maximal amount of data accuracy that can be provided while maintaining privacy. @Gupta:2012:ICP:2238936.2238961 establish a mechanism that is universally optimal for a broad class of data users, suggesting that technical efficiency could be guaranteed in private data publication without the need to learn about the preferences or side information of data consumers. However, @BrennerNissim:Impossibility:SIAM:2014 showed that their result is not generalizable to broader types of data publication.
@Nissim:2012:PMD:2229012.2229073 provide a clear and instructive illustration of how individual preferences for privacy can be modeled in mechanism design problems. 

Several papers are more directly relevant to understanding how privacy affects the work of statistical agencies.
@cummings:empirical:corr:2014 argue that privacy concerns can affect the way people report data, and show how, if properly designed, privacy protection may mitigate misreporting.
While there are vast number of papers on the implementation of differentially private publication algorithms, a few are particularly relevant to how statistical agencies operate. @Hardt:Simple:NIPS:2012 and @Hardt:Multiplicative:FOCS10 provide the methods and theory for publication through online query systems. One problem with these methods is that their implementation depends on the underlying data. By contrast, @li:matrix:VLDB:2015 introduce the Matrix Mechanism, which is data-independent, but also can provide high accuracy for reasonable levels of privacy. This is one of the methods under development for use with the 2020 Decennial Census. Other formal privacy systems currently in use at Census are documented in @Machanavajjhala:OTM:ICDE:2008
and @HaneySIGMOD2017. For practitioners, @Machanavajjhala:2015:DSP:2739250.2660766 provide an accessible and very useful overview of how formal privacy methods might be applied to real-world data publishing tasks.

Finally, so-called "privacy semantics" are mappings between mathematical definitions of privacy and plain language. These are really important for practitioners because there is usually a gap between how laypeople think about privacy and how it is defined in the CS literature. By way of introduction, we recommend @He:Blowfish:ACMSIGMOD:2014, @jorgensen:personalized:ICDE:2015. 

```{r comment, include=FALSE,eval=FALSE}
# The reference @groves:harris-kojetin:2017 is problematic for citeproc
# It was solved by doing the following:
# Convert the primary_dynamic.bib into YAML format:
# /path/to/Rstudio/version/pandoc/pandoc-citeproc --bib2yaml primary_dynamic.bib  > primary_dynamic.yaml
# then extracting manually the @groves:harris-kojetin:2017 citation,
# and formatting the author as a "literal" in the header of THIS file.
```

# Policy and Official Statistics
In January 2017, the Committee on National Statistics released a special panel report focused on developing innovations in the U.S. statistical system focused, in part, on preserving privacy [@groves:harris-kojetin:2017]. 
Their report is essential reading to understand the governing principles and practical needs of the statistical system, particularly as it relates to privacy modernization. For a more applied perspective, @Proc:NSF-Sloan:2017 report the proceedings of an ad hoc workshop on practical privacy held at the Census Bureau. That workshop gathered together academic privacy researchers and Census domain experts to help design formal privacy systems for key data products.
In such meetings, it is necessary to make sure people are speaking the same language. @prewitt:2011 describes the specific meanings of the terms "privacy" and "confidentiality" as they have historically been used at the Census Bureau. 

@Manski2014 offers a framework for thinking about total error in official statistics, which refers to the various ways measured quantities may differ from the concepts of interest, including measurement error, design error, and sampling error. From this perspective, privacy protection is yet another source of error in any statistical system.
Maintaining the public trust is a key factor motivating the interest of statistical agencies in privacy protection. 
The less people trust the system, the less likely they respond accurately, or at all. @Childs:Confidence:SP:2015 discuss recent statistics on trust in official statistics and their implications for data collection.
Finally, @HaneySIGMOD2017 and @Holan2010 are good examples of the sorts of implementation details one may encounter when applying statistical privacy protections in public data.


# Statistical Disclosure Limitation
Within most national statistical systems, the primary approach to protecting respondent privacy has been *statistical disclosure limitation* or SDL. @anderson:challenges:JOS:2007 describes the history of threats to confidentiality in the U.S. statistical system prior to 1965.  @Fellegi:1972 initiated the statistical analysis of data confidentiality. @Dalenius:Towards:1977 recognized that statistical agencies would need to do more than just protect against direct disclosures, and thus warned against what he called inferential disclosure. His idea was formalized by @Duncan:Lambert:1986, and provides the ultimate rationale for formal privacy in national statistics. 
 
@abowdschmutteBPEA2015 review the SDL methods currently in use and discuss their application to economic data. They argue that the analysis of SDL-laden data is inherently compromised because the details of the SDL protections cannot be disclosed. If they cannot be disclosed, their consequences for inference are unknowable, and, as they show, potentially large. @Garfinkel:Deidentification:NIST:2015 discusses techniques for de-identifying data and the many ways in which modern computing tools and a data-rich environment may render effective de-identification impossible.
Finally, @spwp22 provides the most comprehensive review of SDL methods currently in use across the U.S. statistical system. 

# Economics of Privacy
There is a large and robust literature on privacy in economics. That literature is generally focused on the value to individuals of being able to conceal private information, like a health condition, from a firm or prospective employer. 
The challenge to the firm is to design mechanisms, like pricing strategies, that encourage people to disclose private information. For an overview of ideas in this literature, we recommend reading @stigler1980introduction, @posner1981economics, and @hirshleifer1980privacy, which appeared in an early symposium. @Varian2002 and @acquisti:taylor:wagman:2015 both provide comprehensive surveys at different points in the development of this literature.

Very few papers tie the economics of privacy directly to official statistics. @Campbell:Privacy:JEMS discuss the consequences for firm profits and individual welfare of data privacy restrictions in California, which prevent firms from sharing certain types of mortgage data. @Goldfarb:Shifts:AERPP:2012 discuss shifts in privacy attitudes and their implications for firms.  @Hsu:EconomicEpsilon:IEEE:2014, address the question of optimal privacy protection from a very similar perspective to @AbowdSchmutte:Privacy:AER. Finally, @Ohm:Broken:UCLALR:2010 surveys the economic implications of contemporary threats to data privacy from a legal perspective.


# Value of Privacy and Data Accuracy
One key challenge for implementing formal privacy systems lies in choosing the amount, or type, of privacy to provide. Answering this question requires some way to understand the individual and social value of privacy. @Ghosh:Auction:GEB:2015 and @Li2014 both model mechanisms for pricing private data under the assumption that individuals are only willing to disclose such information if they are paid.

Part of the social value of privacy arises from its relationship to scientific integrity. While the law of information recovery suggests that improved privacy must come at the cost of increased error in published statistics, these effects might be mitigated through two distinct channels. First, people are more truthful in surveys if they believe their data is not at risk, as @couper2008risk illustrate. Second,  work in computer science [@Dwork:Generalization:NIPS:2015 ] and statistics [@cummings:adaptive:corr:2016] suggests another somewhat surprising benefit of differential privacy: protection against overfitting. A complete accounting of the costs and benefits of formal privacy systems should take these channels into account.

It is equally necessary to develop a more robust understanding of why data is valuable in the first place, the overall social cost of increasing error in public statistics. This seems to be an area in which very little comprehensive theoretical or empirical research has been done. We nevertheless recommend what seem to be good starting points.

On the theoretical side, economists studying privacy have also developed models of the value of data to firms. In these models, firms benefit from being able to tailor prices based on individual demand [@Taylor:Consumer:RAND:2004], or from being able to market more effectively [@Varian1998]. More recently, a theoretical literature on information design has begun to consider more effective ways to manage markets for consumer information, see  @10.1257/aer.20161079 and @PomattoTheCostOfInformation2018. The recent literature is related to @Spencer:Optimal:JASA:1985, who developed a decision-theoretic framework for modeling optimal data quality.

On the empirical side, a handful of interesting use cases suggest techniques for uncovering the value of data. For example, @CardAER2012 and @perez-truglia:transparency:SSRN:2016 show how workers respond to pay transparency policies, which give them new information about co-worker salaries. @Seeskin:Spencer:Effects:2015 use a calibration exercise to study the costs, measured in misallocated congressional seats, of reduced accuracy in population census data.


# References

<!-- `r if (knitr::is_html_output()) '# References'` -->

<!-- If you need PDF output, uncomment bookdown::pdf_book above in YAML. You will need a LaTeX installation, e.g., https://yihui.name/tinytex/ -->
